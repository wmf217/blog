---
layout:     post
title:      "kafka"
subtitle:   " \"kafka理论和实践\""
date:       2018-12-08 20:44:00
author:     "wmf"
header-img: "img/in-post/bigdata.jpg"
catalog: true
tags:
    - java
---
## 消息系统
1.点对点模式
2.发布订阅模式
## topic&partition
![](/img/in-post/topic.png)
##### topic
每个发送到kafka的消息都有一个类别，这个类别就是topic(主题)
##### partition
一个topic是由多个partition(分区)组成，一个partition的消息是有序的，但是多个partition之间是不保证有序的
##### offset
kafka支持位移，也就是offset，消费者可以去指定offset下读取数据
![](/img/in-post/offset.png)
## payload
kafka发送消息的内部单元叫payload，以topic来分类，它是一个字节数组，不关心数据的具体格式<br>
每个payload都有一个可选的metadata，被称作key，key同样是一个字节数组<br>
payload被写入partition的是否，key控制分派过程，默认使用hash取模，如果不存在key，使用轮询partition的方式<br>
为了更加高效，payload以批量提交的方式写入kafka，这些payload有相同的topic和partition，它是吞吐和延迟的权衡<br>
*批量提交的触发，一个是达到了预先设置的数据量，一个是达到了预先设置的超时时间*
## Producer&Consumer
Producer生产payload，Consumer订阅一个或多个topic<br>
Consumer自己维护payload的offset<br>
Consumer以Consumer group方式来工作，一个group共同消费一个topic<br>
Consumer group保证topic内的一个partition只会被group中的一个Consumer消费，所以partition一定会被有序消费<br>
group中的consumer出现故障，消费组内的其他消费者会接管它的分区
## kafka的整体架构
![](/img/in-post/kafka1.jpg)
![](/img/in-post/kafka2.jpg)
## kafka的配置
##### broker
broker.id: kafka broker的标识信息<br>
port: 监听端口<br>
zookeeper.connect: zookeeper的连接地址<br>
log.dirs: kafka将消息持久化到磁盘，存在这个目录下<br>
num.recovery.threads.per.data.dir: 数据所对应的目录的线程数(只在启动，恢复数据，关闭时使用，所以可以尽量设大点)<br>
auto.create.topics.enable: 指定的场景下自动创建topic(一般手动设为false，以及时发现没有topic的错误)
###### topic
number.partitions: topic创建时partition个数，默认是1(分区机制可以使得topic可以均衡分布在kafka集群里，很多都把分区数设置成broker的数量，或者是broker数量的整数倍)<br>
**设置分区数的考虑因素？首先是你希望的topic吞吐量是多少，单个分区的吞吐量是多少，比如Consumer从partition中读取数据并处理存入数据库的时间是50mb/s，预期的topic吞吐量是1000mb/s，那至少需要20个分区**<br>
log.segment.bytes: 每个segment的最大数据容量，默认1G(Producer在写入消息时，数据存储在日志段的segment文件中，当segment写满了，就会新建一个segment，旧的segment关闭以后过一段时间就会自动删除)<br>
**如果Producer写入速度很慢，这个参数可以适当的做调整，加入一个topic一天只有100mb数据写入，该参数使用默认值1G，需要10天一个segment才会被写满，如果过期时间为7天，那么此时需要17天才可以删除一个segment**<br>
log.segment.ms: segment强制关闭的时间，没有默认值(一旦设置，到了这个时间segment强制关闭，没有默认值，所以默认使用上面的参数用文件的大小来关闭)<br>
**一个需要注意的点-如果有大量的partition，而这些partition的segment都没有达到文件大小上限，那么当达到log.segment.ms的时间时，这些segement会同时被关闭，大量的IO操作会影响IO性能**<br>
message.max.bytes: payload的最大数据量限制，默认是1mb(当Producer发送的数据超过这个值会发送失败)
## kafka发送消息的基本流程
![](/img/in-post/kafka3.jpg)
## kafka的安装启动
```
tar -zxvf kafka2.3.0.tgz
```
kafka的默认启动需要1G内存，如果计算机内存太小，可以调整
```
free -h // 查看内存剩余
find . -iname '*server-start.sh'
vi /export/server/kafka/bin/zookeeper-server-start.sh
vi /export/server/kafka/bin/kafka-server-start.sh
```
将```-Xms1G -Xms1G```修改为```-Xmx400M -Xms400M```(根据需要，试过了128m跑不起来内存溢出)
启动zookeeper集群
```
bin/zkServer.sh start conf/zoo-1.cfg
bin/zkServer.sh start conf/zoo-2.cfg
bin/zkServer.sh start conf/zoo-3.cfg
```
启动kafka
```
bin/kafka-server-start.sh config/server.properties
```
## shell操作kafka
创建一个topic
```
kafka-topics.sh --create --zookeeper 127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183 --partitions 1 --replication-factor 1 --topic wmf
```
解释<br>
--partitions 1   #创建1个分区(当前没有通过集群搭建，所以只能创建一个分区)<br>
--replication-factor 1     #复制1份<br>
--topic     #主题为wmf<br>
查看topic信息
```
bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic wmf
```
显示信息
```
Topic:wmf       PartitionCount:1        ReplicationFactor:1     Configs:
Topic: wmf      Partition: 0    Leader: 0       Replicas: 0     Isr: 0
```
删除topic
```
bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic wmf
```
##### producer发送信息
```
bin/kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic wmf
```
输入信息
```
this is a message from wmf
```
#### consumer接受信息
```
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic wmf --from-beginning
```
获得信息
```
this is a message from wmf
```
即接受到了信息